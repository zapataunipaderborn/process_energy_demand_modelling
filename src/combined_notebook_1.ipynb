{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2060597a",
   "metadata": {},
   "source": [
    "# Comprehensive Process Energy Demand Modelling and Evaluation\n",
    "\n",
    "This notebook provides a unified framework for preprocessing multiple datasets, extracting processes, simulating them, modeling energy profiles, and evaluating results across all datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268c9ddf",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Import all necessary libraries for data processing, process mining, modeling, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57287e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Process mining\n",
    "import pm4py\n",
    "# from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "# from pm4py.objects.conversion.log import converter as log_converter\n",
    "# from pm4py.algo.discovery.alpha import algorithm as alpha_miner\n",
    "# from pm4py.algo.discovery.inductive import algorithm as inductive_miner\n",
    "# from pm4py.simulation.playout import simulator\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Utilities\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c83dd09",
   "metadata": {},
   "source": [
    "## 2. Configuration and Path Setup\n",
    "\n",
    "Define paths for multiple datasets and set configuration parameters for preprocessing and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6bbfb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded for 2 datasets\n",
      "Models to evaluate: ['RandomForest', 'GradientBoosting', 'LinearRegression']\n"
     ]
    }
   ],
   "source": [
    "# Dataset configuration\n",
    "DATASETS = {\n",
    "    'dataset1': {\n",
    "        'path': '/Users/davidzapata/Documents/GitHub/process_energy_demand_modelling/data/silver/company_1/df_sensor_joined.parquet',\n",
    "        'name': 'Dataset 1',\n",
    "        'case_id': 'case:concept:name',\n",
    "        'activity': 'concept:name',\n",
    "        'timestamp': 'time:timestamp',\n",
    "        'energy': 'energy_consumed'\n",
    "    },\n",
    "    'dataset2': {\n",
    "        'path': '/Users/davidzapata/Documents/GitHub/process_energy_demand_modelling/data/silver/company_2/df_combined_legend.parquet',\n",
    "        'name': 'Dataset 2',\n",
    "        'case_id': 'CaseID',\n",
    "        'activity': 'Activity',\n",
    "        'timestamp': 'Timestamp',\n",
    "        'energy': 'EnergyDemand'\n",
    "    },\n",
    "    # Add more datasets as needed\n",
    "}\n",
    "\n",
    "# Modeling configuration\n",
    "CONFIG = {\n",
    "    'test_size': 0.2,\n",
    "    'random_state': 42,\n",
    "    'simulation_traces': 100,\n",
    "    'models': ['RandomForest', 'GradientBoosting', 'LinearRegression']\n",
    "}\n",
    "\n",
    "# Results storage\n",
    "results_dict = {}\n",
    "preprocessed_datasets = {}\n",
    "\n",
    "print(f\"Configuration loaded for {len(DATASETS)} datasets\")\n",
    "print(f\"Models to evaluate: {CONFIG['models']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290466ba",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing Module\n",
    "\n",
    "Create reusable preprocessing functions that handle event log formatting, timestamp conversion, and data cleaning for all datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dee9880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_event_log(dataset_key, config):\n",
    "    \"\"\"\n",
    "    Preprocess event log data for process mining.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    dataset_key : str\n",
    "        Key from DATASETS dictionary\n",
    "    config : dict\n",
    "        Dataset configuration with column mappings\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame : Preprocessed event log\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Preprocessing: {config['name']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Load data\n",
    "    try:\n",
    "        df = pd.read_csv(config['path'])\n",
    "        print(f\"✓ Loaded {len(df)} events from {config['path']}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"✗ File not found: {config['path']}\")\n",
    "        return None\n",
    "    \n",
    "    # Rename columns to standard format\n",
    "    column_mapping = {\n",
    "        config['case_id']: 'case:concept:name',\n",
    "        config['activity']: 'concept:name',\n",
    "        config['timestamp']: 'time:timestamp',\n",
    "        config['energy']: 'energy_consumed'\n",
    "    }\n",
    "    \n",
    "    df = df.rename(columns=column_mapping)\n",
    "    \n",
    "    # Convert timestamp to datetime\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df['time:timestamp']):\n",
    "        df['time:timestamp'] = pd.to_datetime(df['time:timestamp'], errors='coerce')\n",
    "        print(f\"✓ Converted timestamps to datetime format\")\n",
    "    \n",
    "    # Remove rows with missing critical values\n",
    "    initial_len = len(df)\n",
    "    df = df.dropna(subset=['case:concept:name', 'concept:name', 'time:timestamp'])\n",
    "    if len(df) < initial_len:\n",
    "        print(f\"✓ Removed {initial_len - len(df)} rows with missing critical values\")\n",
    "    \n",
    "    # Sort by case and timestamp\n",
    "    df = df.sort_values(['case:concept:name', 'time:timestamp'])\n",
    "    print(f\"✓ Sorted by case and timestamp\")\n",
    "    \n",
    "    # Add additional features\n",
    "    df['hour'] = df['time:timestamp'].dt.hour\n",
    "    df['day_of_week'] = df['time:timestamp'].dt.dayofweek\n",
    "    df['month'] = df['time:timestamp'].dt.month\n",
    "    \n",
    "    # Calculate duration (time since last event in case)\n",
    "    df['duration'] = df.groupby('case:concept:name')['time:timestamp'].diff().dt.total_seconds()\n",
    "    df['duration'] = df['duration'].fillna(0)\n",
    "    \n",
    "    print(f\"✓ Added temporal features (hour, day_of_week, month, duration)\")\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(f\"\\nDataset Summary:\")\n",
    "    print(f\"  - Total events: {len(df)}\")\n",
    "    print(f\"  - Unique cases: {df['case:concept:name'].nunique()}\")\n",
    "    print(f\"  - Unique activities: {df['concept:name'].nunique()}\")\n",
    "    print(f\"  - Date range: {df['time:timestamp'].min()} to {df['time:timestamp'].max()}\")\n",
    "    \n",
    "    if 'energy_consumed' in df.columns:\n",
    "        print(f\"  - Energy range: {df['energy_consumed'].min():.2f} to {df['energy_consumed'].max():.2f}\")\n",
    "        print(f\"  - Mean energy: {df['energy_consumed'].mean():.2f}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def apply_preprocessing_to_all():\n",
    "    \"\"\"\n",
    "    Apply preprocessing to all configured datasets.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary of preprocessed dataframes\n",
    "    \"\"\"\n",
    "    preprocessed = {}\n",
    "    \n",
    "    for dataset_key, dataset_config in DATASETS.items():\n",
    "        df = preprocess_event_log(dataset_key, dataset_config)\n",
    "        if df is not None:\n",
    "            preprocessed[dataset_key] = df\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Preprocessing Complete: {len(preprocessed)}/{len(DATASETS)} datasets processed\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    return preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9eba8e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Preprocessing: Dataset 1\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x80 in position 7: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Execute preprocessing for all datasets\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m preprocessed_datasets \u001b[38;5;241m=\u001b[39m \u001b[43mapply_preprocessing_to_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 89\u001b[0m, in \u001b[0;36mapply_preprocessing_to_all\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m preprocessed \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset_key, dataset_config \u001b[38;5;129;01min\u001b[39;00m DATASETS\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 89\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_event_log\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     91\u001b[0m         preprocessed[dataset_key] \u001b[38;5;241m=\u001b[39m df\n",
      "Cell \u001b[0;32mIn[7], line 22\u001b[0m, in \u001b[0;36mpreprocess_event_log\u001b[0;34m(dataset_key, config)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Load data\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 22\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpath\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✓ Loaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m events from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/htp/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/htp/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda3/envs/htp/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/htp/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1898\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1895\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1897\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1898\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1899\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/htp/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype_backend\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[43mparsers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTextReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[0;32mpandas/_libs/parsers.pyx:574\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/parsers.pyx:663\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/parsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/parsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/parsers.pyx:2053\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x80 in position 7: invalid start byte"
     ]
    }
   ],
   "source": [
    "# Execute preprocessing for all datasets\n",
    "preprocessed_datasets = apply_preprocessing_to_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c99c2d",
   "metadata": {},
   "source": [
    "## 4. Process Discovery and Simulation\n",
    "\n",
    "Extract process models from preprocessed event logs and generate simulated traces for each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8764cf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discover_and_simulate_process(df, dataset_name, num_traces=100):\n",
    "    \"\"\"\n",
    "    Discover process model and simulate traces.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Preprocessed event log\n",
    "    dataset_name : str\n",
    "        Name of the dataset for logging\n",
    "    num_traces : int\n",
    "        Number of traces to simulate\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple : (original_log, simulated_log, process_model)\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Process Discovery: {dataset_name} ---\")\n",
    "    \n",
    "    # Convert to PM4Py event log\n",
    "    log = log_converter.apply(df, variant=log_converter.Variants.TO_EVENT_LOG)\n",
    "    print(f\"✓ Converted to event log format\")\n",
    "    \n",
    "    # Discover process model using Inductive Miner\n",
    "    try:\n",
    "        net, initial_marking, final_marking = inductive_miner.apply(log)\n",
    "        print(f\"✓ Process model discovered using Inductive Miner\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error in process discovery: {e}\")\n",
    "        return None, None, None\n",
    "    \n",
    "    # Simulate process traces\n",
    "    try:\n",
    "        simulated_log = simulator.apply(\n",
    "            net, \n",
    "            initial_marking, \n",
    "            final_marking,\n",
    "            parameters={\n",
    "                simulator.Variants.STOCHASTIC_PLAYOUT.value.Parameters.NO_TRACES: num_traces\n",
    "            }\n",
    "        )\n",
    "        print(f\"✓ Simulated {len(simulated_log)} process traces\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error in simulation: {e}\")\n",
    "        return log, None, (net, initial_marking, final_marking)\n",
    "    \n",
    "    return log, simulated_log, (net, initial_marking, final_marking)\n",
    "\n",
    "\n",
    "def convert_simulated_log_to_df(simulated_log, original_df):\n",
    "    \"\"\"\n",
    "    Convert simulated log to DataFrame with features from original data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    simulated_log : EventLog\n",
    "        Simulated event log from PM4Py\n",
    "    original_df : pd.DataFrame\n",
    "        Original preprocessed dataframe for feature mapping\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame : Simulated events as dataframe\n",
    "    \"\"\"\n",
    "    simulated_data = []\n",
    "    \n",
    "    for trace_idx, trace in enumerate(simulated_log):\n",
    "        for event_idx, event in enumerate(trace):\n",
    "            event_dict = {\n",
    "                'case:concept:name': f\"simulated_case_{trace_idx}\",\n",
    "                'concept:name': event['concept:name'],\n",
    "                'event_id': event_idx\n",
    "            }\n",
    "            simulated_data.append(event_dict)\n",
    "    \n",
    "    simulated_df = pd.DataFrame(simulated_data)\n",
    "    \n",
    "    # Add features based on original data patterns\n",
    "    activity_features = original_df.groupby('concept:name').agg({\n",
    "        'energy_consumed': 'mean',\n",
    "        'duration': 'mean',\n",
    "        'hour': lambda x: x.mode()[0] if len(x.mode()) > 0 else 12,\n",
    "        'day_of_week': lambda x: x.mode()[0] if len(x.mode()) > 0 else 0\n",
    "    }).reset_index()\n",
    "    \n",
    "    simulated_df = simulated_df.merge(activity_features, on='concept:name', how='left')\n",
    "    \n",
    "    print(f\"✓ Converted simulated log to DataFrame with {len(simulated_df)} events\")\n",
    "    \n",
    "    return simulated_df\n",
    "\n",
    "\n",
    "# Process discovery and simulation for all datasets\n",
    "simulated_datasets = {}\n",
    "\n",
    "for dataset_key, df in preprocessed_datasets.items():\n",
    "    dataset_name = DATASETS[dataset_key]['name']\n",
    "    original_log, simulated_log, model = discover_and_simulate_process(\n",
    "        df, \n",
    "        dataset_name, \n",
    "        CONFIG['simulation_traces']\n",
    "    )\n",
    "    \n",
    "    if simulated_log is not None:\n",
    "        simulated_df = convert_simulated_log_to_df(simulated_log, df)\n",
    "        simulated_datasets[dataset_key] = {\n",
    "            'original': df,\n",
    "            'simulated': simulated_df,\n",
    "            'model': model\n",
    "        }\n",
    "\n",
    "print(f\"\\nProcess discovery and simulation complete for {len(simulated_datasets)} datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4234036",
   "metadata": {},
   "source": [
    "## 5. Energy Profile Modeling\n",
    "\n",
    "Apply energy demand modeling to the simulated processes, creating energy profiles for each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34b8fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features_for_modeling(df):\n",
    "    \"\"\"\n",
    "    Prepare features for machine learning models.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Event log dataframe\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple : (X, y, feature_names)\n",
    "    \"\"\"\n",
    "    # Encode categorical features\n",
    "    le = LabelEncoder()\n",
    "    df_model = df.copy()\n",
    "    \n",
    "    if 'concept:name' in df_model.columns:\n",
    "        df_model['activity_encoded'] = le.fit_transform(df_model['concept:name'])\n",
    "    \n",
    "    # Select features\n",
    "    feature_cols = ['activity_encoded', 'hour', 'day_of_week', 'duration', 'event_id']\n",
    "    available_features = [col for col in feature_cols if col in df_model.columns]\n",
    "    \n",
    "    X = df_model[available_features].fillna(0)\n",
    "    y = df_model['energy_consumed'].fillna(df_model['energy_consumed'].mean())\n",
    "    \n",
    "    return X, y, available_features\n",
    "\n",
    "\n",
    "def train_energy_models(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Train multiple energy prediction models.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train, y_train : Training data\n",
    "    X_test, y_test : Test data\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Trained models and their predictions\n",
    "    \"\"\"\n",
    "    models = {\n",
    "        'RandomForest': RandomForestRegressor(n_estimators=100, random_state=CONFIG['random_state']),\n",
    "        'GradientBoosting': GradientBoostingRegressor(n_estimators=100, random_state=CONFIG['random_state']),\n",
    "        'LinearRegression': LinearRegression()\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        \n",
    "        results[model_name] = {\n",
    "            'model': model,\n",
    "            'y_pred_train': y_pred_train,\n",
    "            'y_pred_test': y_pred_test\n",
    "        }\n",
    "        \n",
    "        print(f\"✓ Trained {model_name}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Train models for all datasets\n",
    "model_results = {}\n",
    "\n",
    "for dataset_key, dataset in simulated_datasets.items():\n",
    "    dataset_name = DATASETS[dataset_key]['name']\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Energy Profile Modeling: {dataset_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Use simulated data for modeling\n",
    "    df = dataset['simulated']\n",
    "    \n",
    "    # Prepare features\n",
    "    X, y, feature_names = prepare_features_for_modeling(df)\n",
    "    print(f\"✓ Prepared {len(feature_names)} features: {feature_names}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, \n",
    "        test_size=CONFIG['test_size'], \n",
    "        random_state=CONFIG['random_state']\n",
    "    )\n",
    "    print(f\"✓ Split data: {len(X_train)} training, {len(X_test)} test samples\")\n",
    "    \n",
    "    # Train models\n",
    "    trained_models = train_energy_models(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    model_results[dataset_key] = {\n",
    "        'name': dataset_name,\n",
    "        'X_train': X_train,\n",
    "        'X_test': X_test,\n",
    "        'y_train': y_train,\n",
    "        'y_test': y_test,\n",
    "        'models': trained_models,\n",
    "        'features': feature_names\n",
    "    }\n",
    "\n",
    "print(f\"\\nEnergy modeling complete for {len(model_results)} datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33a7aa1",
   "metadata": {},
   "source": [
    "## 6. Comprehensive Evaluation Framework\n",
    "\n",
    "Implement evaluation metrics and comparison logic to assess model performance across all datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd143830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred, model_name, dataset_name, split='test'):\n",
    "    \"\"\"\n",
    "    Evaluate model performance with multiple metrics.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_true : array-like\n",
    "        True values\n",
    "    y_pred : array-like\n",
    "        Predicted values\n",
    "    model_name : str\n",
    "        Name of the model\n",
    "    dataset_name : str\n",
    "        Name of the dataset\n",
    "    split : str\n",
    "        'train' or 'test'\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Evaluation metrics\n",
    "    \"\"\"\n",
    "    metrics = {\n",
    "        'Dataset': dataset_name,\n",
    "        'Model': model_name,\n",
    "        'Split': split,\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        'MAE': mean_absolute_error(y_true, y_pred),\n",
    "        'R2': r2_score(y_true, y_pred),\n",
    "        'MAPE': np.mean(np.abs((y_true - y_pred) / y_true)) * 100 if not np.any(y_true == 0) else np.nan\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def comprehensive_evaluation(model_results):\n",
    "    \"\"\"\n",
    "    Perform comprehensive evaluation across all datasets and models.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model_results : dict\n",
    "        Dictionary containing model results for all datasets\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame : Evaluation results\n",
    "    \"\"\"\n",
    "    all_evaluations = []\n",
    "    \n",
    "    for dataset_key, results in model_results.items():\n",
    "        dataset_name = results['name']\n",
    "        \n",
    "        print(f\"\\n--- Evaluating: {dataset_name} ---\")\n",
    "        \n",
    "        for model_name, model_data in results['models'].items():\n",
    "            # Evaluate on training set\n",
    "            train_metrics = evaluate_model(\n",
    "                results['y_train'],\n",
    "                model_data['y_pred_train'],\n",
    "                model_name,\n",
    "                dataset_name,\n",
    "                'train'\n",
    "            )\n",
    "            all_evaluations.append(train_metrics)\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            test_metrics = evaluate_model(\n",
    "                results['y_test'],\n",
    "                model_data['y_pred_test'],\n",
    "                model_name,\n",
    "                dataset_name,\n",
    "                'test'\n",
    "            )\n",
    "            all_evaluations.append(test_metrics)\n",
    "            \n",
    "            print(f\"  {model_name:20s} - Test R2: {test_metrics['R2']:.4f}, RMSE: {test_metrics['RMSE']:.4f}\")\n",
    "    \n",
    "    evaluation_df = pd.DataFrame(all_evaluations)\n",
    "    \n",
    "    return evaluation_df\n",
    "\n",
    "\n",
    "# Perform comprehensive evaluation\n",
    "evaluation_results = comprehensive_evaluation(model_results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUATION COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTotal evaluations: {len(evaluation_results)}\")\n",
    "print(f\"Datasets: {evaluation_results['Dataset'].nunique()}\")\n",
    "print(f\"Models: {evaluation_results['Model'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdd756a",
   "metadata": {},
   "source": [
    "## 7. Results Aggregation and Comparison\n",
    "\n",
    "Collect, aggregate, and visualize evaluation results for all datasets in comparative tables and charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644e5899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display test set results\n",
    "test_results = evaluation_results[evaluation_results['Split'] == 'test'].copy()\n",
    "\n",
    "print(\"TEST SET PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(test_results.to_string(index=False))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b260019b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate best model for each dataset\n",
    "best_models = test_results.loc[test_results.groupby('Dataset')['R2'].idxmax()]\n",
    "\n",
    "print(\"\\nBEST MODEL FOR EACH DATASET (by R² Score)\")\n",
    "print(\"=\"*80)\n",
    "print(best_models[['Dataset', 'Model', 'R2', 'RMSE', 'MAE']].to_string(index=False))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d37f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 1: R² Score Comparison\n",
    "fig = px.bar(\n",
    "    test_results,\n",
    "    x='Dataset',\n",
    "    y='R2',\n",
    "    color='Model',\n",
    "    barmode='group',\n",
    "    title='R² Score Comparison Across Datasets and Models',\n",
    "    labels={'R2': 'R² Score', 'Dataset': 'Dataset'},\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Dataset\",\n",
    "    yaxis_title=\"R² Score\",\n",
    "    legend_title=\"Model\",\n",
    "    font=dict(size=12)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d13407c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 2: RMSE Comparison\n",
    "fig = px.bar(\n",
    "    test_results,\n",
    "    x='Dataset',\n",
    "    y='RMSE',\n",
    "    color='Model',\n",
    "    barmode='group',\n",
    "    title='RMSE Comparison Across Datasets and Models',\n",
    "    labels={'RMSE': 'Root Mean Squared Error', 'Dataset': 'Dataset'},\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Dataset\",\n",
    "    yaxis_title=\"RMSE\",\n",
    "    legend_title=\"Model\",\n",
    "    font=dict(size=12)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b8820a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 3: Heatmap of R² scores\n",
    "pivot_r2 = test_results.pivot(index='Model', columns='Dataset', values='R2')\n",
    "\n",
    "fig = px.imshow(\n",
    "    pivot_r2,\n",
    "    labels=dict(x=\"Dataset\", y=\"Model\", color=\"R² Score\"),\n",
    "    title=\"R² Score Heatmap: Models vs Datasets\",\n",
    "    aspect=\"auto\",\n",
    "    color_continuous_scale='RdYlGn',\n",
    "    text_auto='.3f'\n",
    ")\n",
    "\n",
    "fig.update_layout(height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750bd709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 4: Performance metrics summary\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Comprehensive Model Performance Comparison', fontsize=16, fontweight='bold')\n",
    "\n",
    "metrics = ['R2', 'RMSE', 'MAE', 'MAPE']\n",
    "titles = ['R² Score (Higher is Better)', 'RMSE (Lower is Better)', \n",
    "          'MAE (Lower is Better)', 'MAPE (Lower is Better)']\n",
    "\n",
    "for idx, (metric, title) in enumerate(zip(metrics, titles)):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    \n",
    "    pivot_data = test_results.pivot(index='Model', columns='Dataset', values=metric)\n",
    "    pivot_data.plot(kind='bar', ax=ax, width=0.8)\n",
    "    \n",
    "    ax.set_title(title, fontweight='bold')\n",
    "    ax.set_xlabel('Model')\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.legend(title='Dataset', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6162402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"\\nOVERALL PERFORMANCE STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for metric in ['R2', 'RMSE', 'MAE']:\n",
    "    print(f\"\\n{metric}:\")\n",
    "    summary = test_results.groupby('Model')[metric].agg(['mean', 'std', 'min', 'max'])\n",
    "    print(summary.to_string())\n",
    "    print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a92588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results to CSV\n",
    "output_path = '/Users/davidzapata/Documents/GitHub/process_energy_demand_modelling/evaluation_results.csv'\n",
    "evaluation_results.to_csv(output_path, index=False)\n",
    "print(f\"\\n✓ Evaluation results exported to: {output_path}\")\n",
    "\n",
    "# Export best models summary\n",
    "best_models_path = '/Users/davidzapata/Documents/GitHub/process_energy_demand_modelling/best_models_summary.csv'\n",
    "best_models.to_csv(best_models_path, index=False)\n",
    "print(f\"✓ Best models summary exported to: {best_models_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e95a6a",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook provides a complete pipeline for:\n",
    "\n",
    "1. **Preprocessing** multiple event log datasets with standardized formatting\n",
    "2. **Process Discovery** using PM4Py's inductive miner\n",
    "3. **Simulation** of process traces for model training\n",
    "4. **Energy Modeling** using multiple machine learning algorithms\n",
    "5. **Comprehensive Evaluation** across all datasets and models\n",
    "6. **Results Visualization** for easy comparison and interpretation\n",
    "\n",
    "### Key Findings:\n",
    "- Compare model performance across different datasets\n",
    "- Identify the best-performing model for each dataset\n",
    "- Understand trade-offs between different modeling approaches\n",
    "- Export results for further analysis and reporting\n",
    "\n",
    "### Next Steps:\n",
    "- Fine-tune hyperparameters for best-performing models\n",
    "- Add additional datasets to the evaluation\n",
    "- Experiment with advanced features engineering\n",
    "- Deploy best models for production use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61cba1f",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook provides a complete pipeline for:\n",
    "\n",
    "1. **Preprocessing** multiple event log datasets with standardized formatting\n",
    "2. **Process Discovery** using PM4Py's inductive miner\n",
    "3. **Simulation** of process traces for model training\n",
    "4. **Energy Modeling** using multiple machine learning algorithms\n",
    "5. **Comprehensive Evaluation** across all datasets and models\n",
    "6. **Results Visualization** for easy comparison and interpretation\n",
    "\n",
    "### Key Findings:\n",
    "- Compare model performance across different datasets\n",
    "- Identify the best-performing model for each dataset\n",
    "- Understand trade-offs between different modeling approaches\n",
    "- Export results for further analysis and reporting\n",
    "\n",
    "### Next Steps:\n",
    "- Fine-tune hyperparameters for best-performing models\n",
    "- Add additional datasets to the evaluation\n",
    "- Experiment with advanced features engineering\n",
    "- Deploy best models for production use"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "htp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
